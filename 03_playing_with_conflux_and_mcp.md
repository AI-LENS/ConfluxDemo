# Using Conflux with MCP Servers

Now that you have Conflux and your MCP servers set up, let’s see how to use them together to build a smart agent that can answer real-world questions using external tools—like fetching stock prices!

## 1. Example: Querying Stock Prices with Conflux and MCP

We’ll use the [Conflux](https://github.com/conflux-ai/conflux) library to build a simple agent that asks for the stock price of the Nifty 50 index for a specific date. The agent will use an MCP server (Yahoo Finance) as a tool, and an LLM (like OpenAI) to generate a comprehensive answer.

### Step-by-Step Code Walkthrough

Create a new file called `02_conflux_and_mcp.py` in your `my-project` folder and copy the following code:

```python
import asyncio
import os

from conflux import HandlerChain, Message, handler
from conflux.handlers import McpToolCall, OpenAiLLM

# Set your OpenAI API key here
os.environ["OPENAI_API_KEY"] = "YOUR-API-KEY"

# Configure the MCP server (Yahoo Finance)
config = {
    "mcpServers": {"explorer": {"url": "http://localhost:9090/yahoo-finance/sse"}}
}

@handler
async def fetch_tool_list(msg: Message, chain: HandlerChain) -> str:
    chain.variables["query"] = msg.primary
    return f"User query: {msg.primary}?"

@handler
async def answer(msg: Message, chain: HandlerChain) -> str:
    return (
        f"Please answer the following query:\n{chain.variables['query']}\n\n"
        f"Here is the result from the relevant tool for the query:\n{msg}\n\n"
        "Provide a comprehensive answer to the query using the tool result."
    )

def main():
    chain = (
        fetch_tool_list
        >> McpToolCall(config=config, llm=OpenAiLLM)
        >> answer
        >> OpenAiLLM()
    )
    return asyncio.run(
        chain.run(
            "What is the stock price of nifty 50 (^NSEI) yesterday (22-05-2025)?",
        )
    )

if __name__ == "__main__":
    result = main()
    print(result)
```

**Don’t forget:** Replace `"YOUR-API-KEY"` with your actual OpenAI API key.

### How It Works

- **fetch_tool_list**: Takes the user’s question and stores it in the chain’s variables.
- **McpToolCall**: Calls the Yahoo Finance MCP server to fetch the relevant data.
- **answer**: Prepares a prompt for the LLM to generate a comprehensive answer using the tool’s result.
- **OpenAiLLM**: Uses OpenAI to generate the final answer.

## 2. Run the Example

Make sure your MCP proxy and Yahoo Finance server are running (see the previous section). Then, in your terminal, run:

```powershell
uv run 02_conflux_and_mcp.py
```

You should see an answer with the stock price for the given date, generated by the LLM using the data fetched from the MCP server.

---

You’ve now connected Conflux with external tools using MCP servers! You can extend this pattern to connect to any tool or API supported by MCP. Experiment with different queries and tools to build your own smart agents.

If you have questions or want to learn more, check out the [Conflux documentation](https://github.com/conflux-ai/conflux) and [MCP Proxy documentation](https://github.com/TBXark/mcp-proxy).
